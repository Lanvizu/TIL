### 검증집합과 교차검증을 이용한 모델 선택 알고리즘

훈련집합과 테스트집합과 다른 별도의 검증집합을 가진 상황

-----

### 검증집합을 이용한 모델 선택

각각의 모델을 훈련집합으로 학습시키고 검증집합으로 학습된 모델의 성능을 측정한다.

가장 높은 성능을 보인 모델을 선택해 테스트 집합으로 선택된 모델의 성능을 측정한다.

-----

### 교차검증 (cross vaildation)

비용 문제로 별도의 검증집합이 없는 상황에 유용한 모델 선택 기법

훈련집합을 등분하여, 학습과 평가 과정을 여러 번 반복한 후 평균 사용

훈련집합을 k개의 그룹으로 등분하여 하나씩 성능을 측정한다.

가장 높은 성능을 보인 모델을 선택하여 테스트 집합을 성능을 측정한다.

-----

### 부트스트랩 (boot strap)

난수를 이용한 샘플링 반복

훈련집합 X에서 pn개 샘플을 뽑아 새로운 훈련집합X`으로 구성.

이 때 대치(중복)를 허용한다.

X'으로 모델을 학습시키고 X-X`(나머지 모델)를 이용하여 학습된 모델의 성능을 측정한다.

가장 높은 성능을 보인 모델을 선택하여 테스트 집합으로 성능을 측정한다.

교차 검증과의 차이로는 Cross는 미리 고정하고 측정하지만 부트스트랩은 랜덤으로 정하여 측정한다.

------

### 모델 선택의 한계와 현실적인 해결책

- 현실에서는 경험을 큰 틀을 선택한 후 모델 선택 알고리즘으로 세부 모델을 선택하는 전략을 사용한다.

**현대 기계 학습의 전략**

- 용량이 충분히 큰 모델을 선택한 후, 선택한 모델이 정상을 벗어나지 않도록 여러가지 규제(regularization) 기법을 적용한다.

-----

##규제

### 데이터 확대

- 데이터를 더 많이 수집하면 일반화 능력이 향상된다.

- 하지만 데이터 수집은 많은 비용이 든다. (학습데이터는 항상 부족하다)

- 그라운드 트루스(정답)를 사람이 일일이 레이블링해야 한다.

- 따라서 인위적으로 데이터를 확대한다.

- 훈련집합에 있는 샘플을 변형한다.
  
- 약간 회전하거나 와핑(부류 소속이 변하지 않게 주의)

-----

### 가중치 감쇠

- 가중치를 작게 조절하는 기법
- 가중치 감쇠는 개선된 목적함수를 이용하여 가중치를 작게 조절하는 규제 기법이다.

-----

### 조기 멈춤
- 항상 사용한다고 생각해야된다.
- 학습 시간에 따른 일반화 능력
- 일정 시간이 지나면 과잉적합 현상이 나타남 -> 일반화 능력 저하
- 훈련 데이터에만 Fitting
- 너무 많은 training을 진행할경우 현실에서는 문제가 발생한다.
- 검증 집합의 오류가 최저인 점에서 학습을 멈춘다.

-----

### 앙상블
- 서로 다른 여러 개의 모델을 결합하여 일반화 오류를 줄이는 기법
- 현대 기계 학습은 앙상블도 규제로 여긴다.
