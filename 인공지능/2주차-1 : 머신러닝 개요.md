### 데이터 가시화

4차원 이상의 초공간은 한꺼번에 가시화 불가능
여러 가지 가시화 기법을 통해 고차원 공간을 저차원으로 변환하는 기법을 사용한다.

-----

### 목적 함수 (objective function) 또는 비용 함수 (cost function), 오차 함수(loss function)

- 선형 회귀를 위한 목적 함수
- 예측 함수의 출력과 예측 함수가 맞추어야 하는 목푯값의 차이를 오차라고 표현
- 다음 식을 평균제곱오차 MSE (mean squared error)라고 부른다.

![image](https://github.com/Lanvizu/just_records/assets/121706341/540347a4-8a0d-41b8-8bd4-0680a2c8f254)

처음에는 최적 매개변수 값을 알 수 없으므로 난수로 설정 후 개선해 나가 최적해를 찾는다.

------
### 좀 더 현실적인 상황

지금까지는 데이터가 선형을 이루는 아주 단순한 상황을 고려함
실제 세계는 선형이 아니면 잡음이 섞임 --> 비선형 모델이 필요

-----
### 과소적합과 과잉적합
과소적합 - 모델의 '용량이 작아' 오차가 클 수 밖에 없는 현상

비선형 모델을 사용하는 대안
1차(선형)에 비해 오차가 크게 감소함

### 과잉적합

12차 다항식 곡선을 채택한다면 훈련집합에 대해 거의 완벽하게 근사화함
하지만 '새로운' 데이터를 예측한다면 큰 문제 발생
이유는 '용량이 크기' 때문이다. 학습 과정에서 잡음까지 수용 --> 과잉적합 현상

![image](https://github.com/Lanvizu/just_records/assets/121706341/163571d6-50ed-40c1-8d7d-ae337660bfc9)

적절한 용량의 모델을 선택하는 모델 선택 작업이 필요함

잘못된(튀는) 데이터에 맞춰 학습시키면 새로운 데이터에 대한 오차가 너무 커진다.

-----
### 바이어스와 분산

1~2차는 훈련집합과 테스트집합 모두 낮은 성능
12차는 훈련집합에 높은 성능을 보이나 테스트집합에서는 낮은 성능 -> 낮은 일반화 능력
3~4차는 훈련 집합에 대해 12차보다 낮겠지만 테스트집합에는 높은 성능 -> 높은 일반화 능력

![image](https://github.com/Lanvizu/just_records/assets/121706341/107b1b0c-ebfb-4fba-bf3f-dc765574d770)

훈련집합을 여러 번 수집하여 1차~12차에 적용하는 실험
2차는 매번 큰 오차 -> 바이어스가 큼. 하지만 비슷한 모델을 얻음 -> 낮은 분산
12차는 매번 작은 오차 -> 바이어스가 작음. 하지만 크게 다른 모델을 얻음 -> 높은 분산
일반적으로 용량이 작은 모델은 바이어스는 크고 분산은 작음. 복잡한 모델은 바이어스는 작고 분산은 큼
바이어스와 분산은 트레이드오프 관계

-----
### 기계 학습의 목표
- 낮은 바이어스와 낮은 분산을 가진 예측기 제작이 목표

![image](https://github.com/Lanvizu/just_records/assets/121706341/5e9485ca-926f-40fe-a734-0619629c63b5)

왼쪽 아래와 같은 상황을 의미한다.
하지만 바이어스와 분산은 트레이드오프 관계
따라서 바이어스 희생을 최소로 유지하며 분산을 최대로 낮추는 전략 필요
